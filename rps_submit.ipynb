{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaec3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "445254d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPSTrainer():\n",
    "    # define\n",
    "    def __init__(self):\n",
    "        self.regret_sum = [[0, 0, 0], [0, 0, 0]]\n",
    "        self.strategy = [[0, 0, 0], [0, 0, 0]]  # regret_sumと同じか、負の数なら0。0以上1以下。総計が1\n",
    "        self.strategy_sum = [[0, 0, 0], [0, 0, 0]] # strategyを毎回足し合わせたもの。総計は施行回数と一致\n",
    "    \n",
    "    # get current mixed strategy through regret-matching\n",
    "    def get_strategy(self, player): # 引数を増やして複数のプレイヤーに対応できるようにする\n",
    "        normalizing_sum = 0\n",
    "        self.strategy[player] = [self.regret_sum[player][a] if self.regret_sum[player][a] > 0 else 0 for a in range(3)]\n",
    "        normalizing_sum = sum(self.strategy[player])\n",
    "        if normalizing_sum > 0:\n",
    "            self.strategy[player] = [self.strategy[player][a] / normalizing_sum for a in range(3)]\n",
    "        else:\n",
    "            self.strategy[player] = [1.0 / 3 for a in range(3)]\n",
    "        self.strategy_sum[player] = [self.strategy_sum[player][a] + self.strategy[player][a] for a in range(3)]\n",
    "        return self.strategy[player]\n",
    "    \n",
    "    # get random action according to mixed-strategy distribution\n",
    "    def get_action(self, strategy):\n",
    "        r = np.random.rand()\n",
    "        a = 0\n",
    "        cumulative_probability = 0\n",
    "        while a < 3 - 1:\n",
    "            cumulative_probability += strategy[a]\n",
    "            if r < cumulative_probability:\n",
    "                break\n",
    "            a += 1\n",
    "        return a\n",
    "    \n",
    "    # training algorithm\n",
    "    def train(self, iterations):\n",
    "        action_utility = [0, 0, 0]\n",
    "\n",
    "        for i in range(iterations // 2):\n",
    "            # action_bを固定\n",
    "            # get regret-matched mixed-strategy actions\n",
    "            self.strategy[0] = self.get_strategy(0)\n",
    "            action_a = self.get_action(self.strategy[0]) # 0, 1, 2\n",
    "            action_b = self.get_action(self.strategy[1]) # 0, 1, 2\n",
    "            # compute action utilities\n",
    "            action_utility[action_b] = 0\n",
    "            action_utility[0 if action_b == 2 else action_b + 1] = 1\n",
    "            action_utility[2 if action_b == 0 else action_b - 1] = -1\n",
    "            # accumulate action regrets\n",
    "            for a in range(3):\n",
    "                self.regret_sum[0][a] += action_utility[a] - action_utility[action_a]\n",
    "            \n",
    "            # action_aを固定\n",
    "            self.strategy[1] = self.get_strategy(1)\n",
    "            action_b = self.get_action(self.strategy[1]) # 0, 1, 2\n",
    "            action_a = self.get_action(self.strategy[0]) # 0, 1, 2\n",
    "            action_utility[action_a] = 0\n",
    "            action_utility[0 if action_a == 2 else action_a + 1] = 1\n",
    "            action_utility[2 if action_a == 0 else action_a - 1] = -1\n",
    "            for a in range(3):\n",
    "                self.regret_sum[1][a] += action_utility[a] - action_utility[action_b]\n",
    "    \n",
    "    # get average mixed strategy accross all training iterations (similar to get_strategy function)\n",
    "    def get_average_strategy(self, player): # 両方のaverage strategyを取得したいからプレイヤーごとに取得できるよう引数を増やす\n",
    "        avg_strategy = [0, 0, 0]\n",
    "        normalizing_sum = sum(self.strategy_sum[player])\n",
    "        avg_strategy = [self.strategy_sum[player][a] / normalizing_sum if normalizing_sum > 0 else 1.0/3 for a in range(3)]\n",
    "        return avg_strategy\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d821fa16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3343793114012657, 0.3326342969526716, 0.3329863916460627] [0.33158137778846397, 0.33416248094573864, 0.33425614126579734]\n"
     ]
    }
   ],
   "source": [
    "trainer = RPSTrainer()\n",
    "trainer.train(1000000)\n",
    "print(trainer.get_average_strategy(0), trainer.get_average_strategy(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca867873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedTrainer():\n",
    "    # define\n",
    "    def __init__(self):\n",
    "        self.regret_sum = [0, 0, 0]\n",
    "        self.strategy = [0, 0, 0]  # regret_sumと同じか、負の数なら0。0以上1以下。総計が1\n",
    "        self.strategy_sum = [0, 0, 0] # strategyを毎回足し合わせたもの。総計は施行回数と一致\n",
    "        self.op_strategy = [0.4, 0.3, 0.3]\n",
    "    \n",
    "    # get current mixed strategy through regret-matching\n",
    "    def get_strategy(self): # 引数を増やして複数のプレイヤーに対応できるようにする\n",
    "        normalizing_sum = 0\n",
    "        self.strategy = [self.regret_sum[a] if self.regret_sum[a] > 0 else 0 for a in range(3)]\n",
    "        normalizing_sum = sum(self.strategy)\n",
    "        if normalizing_sum > 0:\n",
    "            self.strategy = [self.strategy[a] / normalizing_sum for a in range(3)]\n",
    "        else:\n",
    "            self.strategy = [1.0 / 3 for a in range(3)]\n",
    "        self.strategy_sum = [self.strategy_sum[a] + self.strategy[a] for a in range(3)]\n",
    "        return self.strategy\n",
    "    \n",
    "    # get random action according to mixed-strategy distribution\n",
    "    def get_action(self, strategy):\n",
    "        r = np.random.rand()\n",
    "        a = 0\n",
    "        cumulative_probability = 0\n",
    "        while a < 3 - 1:\n",
    "            cumulative_probability += strategy[a]\n",
    "            if r < cumulative_probability:\n",
    "                break\n",
    "            a += 1\n",
    "        return a\n",
    "    \n",
    "    # training algorithm\n",
    "    def train(self, iterations):\n",
    "        action_utility = [0, 0, 0]\n",
    "        for i in range(iterations):\n",
    "            # get regret-matched mixed-strategy actions\n",
    "            self.strategy = self.get_strategy()\n",
    "            action_a = self.get_action(self.strategy) # 0, 1, 2\n",
    "            action_b = self.get_action(self.op_strategy) # 0, 1, 2\n",
    "            # compute action utilities\n",
    "            action_utility[action_b] = 0\n",
    "            action_utility[0 if action_b == 2 else action_b + 1] = 1\n",
    "            action_utility[2 if action_b == 0 else action_b - 1] = -1\n",
    "            # accumulate action regrets\n",
    "            for a in range(3):\n",
    "                self.regret_sum[a] += action_utility[a] - action_utility[action_a]\n",
    "            \n",
    "    \n",
    "    # get average mixed strategy accross all training iterations (similar to get_strategy function)\n",
    "    def get_average_strategy(self): # 両方のaverage strategyを取得したいからプレイヤーごとに取得できるよう引数を増やす\n",
    "        avg_strategy = [0, 0, 0]\n",
    "        normalizing_sum = sum(self.strategy_sum)\n",
    "        avg_strategy = [self.strategy_sum[a] / normalizing_sum if normalizing_sum > 0 else 1.0/3 for a in range(3)]\n",
    "        return avg_strategy\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d01231fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0064746897049004284, 0.9934762203480096, 4.908994708994707e-05]\n"
     ]
    }
   ],
   "source": [
    "fixed_trainer = FixedTrainer()\n",
    "fixed_trainer.train(100000)\n",
    "print(fixed_trainer.get_average_strategy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6852a13f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
